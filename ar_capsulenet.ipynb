{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from keras import layers, models, optimizers, callbacks, regularizers, activations, layers, initializers\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from keras.layers import Dense, Input, Activation, Reshape, Add\n",
    "import tensorflow as tf\n",
    "from ar_capsulelayers import *\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "def AR_CapsNet(input_shape, args):\n",
    "    dim_caps = int(args.dimcaps)\n",
    "    layernum = int(args.layernum)\n",
    "    print('layer num : ', layernum)\n",
    "    print('dim_caps : ', dim_caps)\n",
    "    \n",
    "    kernel_regularizer=regularizers.l2(0)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    conv1 = Conv2d_bn(input_tensor = input_layer, filters=64, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                     kernel_regularizer=kernel_regularizer)\n",
    "    conv1 = Conv2d_bn(input_tensor = conv1, filters=64, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                     kernel_regularizer=kernel_regularizer)\n",
    "    \n",
    "    ## Primary Capsules\n",
    "    primarycaps = PrimaryCap(n_channels=8, dim_capsule=16, decrease_resolution=True, kernel_regularizer=kernel_regularizer)(conv1)\n",
    "    primarycaps = Activation('tanh')(primarycaps)\n",
    "    print('primary caps shape : ', primarycaps.shape)\n",
    "        \n",
    "    ## Convolutional Capsules\n",
    "    if layernum == 0:\n",
    "        out = primarycaps\n",
    "    elif layernum == 1:\n",
    "        ConvCaps1 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = True, kernel_regularizer=kernel_regularizer)(primarycaps)\n",
    "        ConvCaps1 = Activation('tanh')(ConvCaps1)\n",
    "        print('ConvCaps1 shape : ', ConvCaps1.shape)\n",
    "        out = ConvCaps1\n",
    "        \n",
    "    elif layernum == 2:\n",
    "        ConvCaps1 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = True, kernel_regularizer=kernel_regularizer)(primarycaps)\n",
    "        ConvCaps1 = Activation('tanh')(ConvCaps1)\n",
    "        print('ConvCaps1 shape : ', ConvCaps1.shape)\n",
    "        \n",
    "        ConvCaps2 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = False, kernel_regularizer=kernel_regularizer)(ConvCaps1)\n",
    "        ConvCaps2 = Activation('tanh')(Add()([ConvCaps1 , ConvCaps2]))\n",
    "        print('ConvCaps2 shape : ', ConvCaps2.shape)\n",
    "        out = ConvCaps2\n",
    "        \n",
    "    elif layernum == 3:\n",
    "        ConvCaps1 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = True, kernel_regularizer=kernel_regularizer)(primarycaps)\n",
    "        ConvCaps1 = Activation('tanh')(ConvCaps1)\n",
    "        print('ConvCaps1 shape : ', ConvCaps1.shape)\n",
    "        \n",
    "        ConvCaps2 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = False, kernel_regularizer=kernel_regularizer)(ConvCaps1)\n",
    "        ConvCaps2 = Activation('tanh')(Add()([ConvCaps1 , ConvCaps2]))\n",
    "        print('ConvCaps2 shape : ', ConvCaps2.shape)\n",
    "        \n",
    "        ConvCaps3 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = False, kernel_regularizer=kernel_regularizer)(ConvCaps2)\n",
    "        ConvCaps3 = Activation('tanh')(Add()([ConvCaps2 , ConvCaps3]))\n",
    "        print('ConvCaps3 shape : ', ConvCaps3.shape)\n",
    "        out = ConvCaps3\n",
    "        \n",
    "    ## Fully Convolutional Capsules\n",
    "    output_dim_capsule = dim_caps \n",
    "    outputs = FullyConvCaps(n_channels=10, dim_capsule=output_dim_capsule, kernel_regularizer=kernel_regularizer)(out)\n",
    "    outputs = Activation('tanh')(outputs)\n",
    "    print('Final Routing caps shape : ', outputs.shape)\n",
    "    \n",
    "    ## Length Capsules\n",
    "    real_outputs = Length()(outputs)\n",
    "    print('Length shape : ', real_outputs.shape)\n",
    "\n",
    "    n_class=10\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([outputs, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(outputs)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "    # Shared Decoder model in training and prediction\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(Dense(512, activation='relu', input_dim=output_dim_capsule*n_class, kernel_regularizer=kernel_regularizer))\n",
    "    decoder.add(Dense(512, activation='relu', kernel_regularizer=kernel_regularizer))\n",
    "    decoder.add(Dense(np.prod(input_shape), activation='sigmoid', kernel_regularizer=kernel_regularizer))\n",
    "    decoder.add(Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "    train_model = models.Model([input_layer, y], [real_outputs, decoder(masked_by_y)])\n",
    "    eval_model = models.Model(input_layer, [real_outputs, decoder(masked)])\n",
    "    perturb_input_model = models.Model([input_layer, y], decoder(masked_by_y))\n",
    "\n",
    "    # manipulate model\n",
    "    noise = layers.Input(shape=(n_class, output_dim_capsule))\n",
    "    noised_outputs = layers.Add()([outputs, noise])\n",
    "    masked_noised_y = Mask()([noised_outputs, y])\n",
    "    manipulate_model = models.Model([input_layer, y, noise], [outputs, decoder(masked_noised_y)])\n",
    "    return train_model\n",
    "    \n",
    "def train(train_model, x_train, y_train, args):\n",
    "    valid_ratio = 0.1*int(args.validratio)\n",
    "    print('valid_ratio', valid_ratio)\n",
    "    \n",
    "    ##########################################################################################################\n",
    "    # Training without data augmentation.\n",
    "    # callbacks\n",
    "    class TimeHistory(callbacks.Callback):\n",
    "        def __init__(self):\n",
    "            self.times = []\n",
    "            \n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.times = []\n",
    "\n",
    "        def on_epoch_begin(self, batch, logs={}):\n",
    "            self.epoch_time_start = time.time()\n",
    "\n",
    "        def on_epoch_end(self, batch, logs={}):\n",
    "            self.times.append(time.time() - self.epoch_time_start)\n",
    "    \n",
    "    time_callback = TimeHistory()\n",
    "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
    "    tb = callbacks.TensorBoard(log_dir=args.save_dir + '/tensorboard-logs',\n",
    "                               batch_size=args.batch_size, histogram_freq=int(args.debug))\n",
    "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_length_1_acc',\n",
    "                                           save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    def lr_schedule(epoch):\n",
    "        lrate = 0.001\n",
    "        if epoch > 50:\n",
    "            lrate = 0.0005\n",
    "        elif epoch > 200:\n",
    "            lrate = 0.0001\n",
    "        return lrate\n",
    "\n",
    "    initial_lr = 0.005\n",
    "    RMSprop = optimizers.RMSprop(lr=initial_lr, rho=0.9, epsilon=1e-08, decay=1e-4)\n",
    "    train_model.compile(optimizer=RMSprop,\n",
    "                      loss=[margin_loss, 'mse'],\n",
    "                      loss_weights=[1., 0.3],\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    if args.augment == 'False':\n",
    "        # Training without data augmentation:\n",
    "        hist = train_model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs, \n",
    "                               validation_split=valid_ratio,\n",
    "                               callbacks=[callbacks.LearningRateScheduler(lr_schedule), log, tb, checkpoint, time_callback])\n",
    "        \n",
    "    elif args.augment == 'True':\n",
    "        from keras.preprocessing.image import ImageDataGenerator\n",
    "        shift_fraction = float(args.shift_fraction)\n",
    "        if args.dataset == 'mnist':\n",
    "            flip = False\n",
    "        elif args.dataset == 'cifar10':\n",
    "            flip = True\n",
    "            \n",
    "        if args.dataset in ['mnist', 'cifar10']:\n",
    "            datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "                rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                # randomly shift images horizontally (fraction of total width)\n",
    "                width_shift_range=shift_fraction,\n",
    "                # randomly shift images vertically (fraction of total height)\n",
    "                height_shift_range=shift_fraction,\n",
    "                shear_range=0.,  # set range for random shear\n",
    "                zoom_range=0.,  # set range for random zoom\n",
    "                channel_shift_range=0.,  # set range for random channel shifts\n",
    "                # set mode for filling points outside the input boundaries\n",
    "                fill_mode='nearest',\n",
    "                cval=0.,  # value used for fill_mode = \"constant\"\n",
    "                horizontal_flip=flip,  # randomly flip images\n",
    "                vertical_flip=False,  # randomly flip images\n",
    "                # set rescaling factor (applied before any other transformation)\n",
    "                rescale=None,\n",
    "                # set function that will be applied on each input\n",
    "                preprocessing_function=None,\n",
    "                # image data format, either \"channels_first\" or \"channels_last\"\n",
    "                data_format=None)\n",
    "        else:\n",
    "            #If args.dataset == 'affnist': shift_fraction = 0.2\n",
    "            datagen = ImageDataGenerator(\n",
    "                    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                    samplewise_center=False,  # set each sample mean to 0\n",
    "                    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                    samplewise_std_normalization=False,  # divide each input by its std\n",
    "                    zca_whitening=False,  # apply ZCA whitening\n",
    "                    zca_epsilon=0,  # epsilon for ZCA whitening\n",
    "                    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                    # randomly shift images horizontally (fraction of total width)\n",
    "                    width_shift_range=0.2,\n",
    "                    # randomly shift images vertically (fraction of total height)\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.,  # set range for random shear\n",
    "                    zoom_range=0.,  # set range for random zoom\n",
    "                    channel_shift_range=0.,  # set range for random channel shifts\n",
    "                    # set mode for filling points outside the input boundaries\n",
    "                    fill_mode='nearest',\n",
    "                    cval=0.,  # value used for fill_mode = \"constant\"\n",
    "                    horizontal_flip=True,  # randomly flip images\n",
    "                    vertical_flip=False,  # randomly flip images\n",
    "                    # set rescaling factor (applied before any other transformation)\n",
    "                    rescale=None,\n",
    "                    # set function that will be applied on each input\n",
    "                    preprocessing_function=None,\n",
    "                    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "                    data_format=None)\n",
    "\n",
    "        def train_generator(x, y, batch_size):\n",
    "            train_datagen = datagen  \n",
    "\n",
    "            generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "            while 1:\n",
    "                x_batch, y_batch = generator.next()\n",
    "                yield ([x_batch, y_batch], [y_batch, x_batch])\n",
    "        \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        if args.dataset in ['mnist', 'cifar10']:\n",
    "            x_train_, x_val_, y_train_, y_val_ = train_test_split(x_train, y_train, test_size=valid_ratio, random_state=42)\n",
    "        else:\n",
    "            from keras.utils import to_categorical\n",
    "            x_train_ = x_train\n",
    "            y_train_ = y_train\n",
    "            x_val_, y_val_ = prepare_affNIST('./affnist/validation.mat')\n",
    "            y_val_ = to_categorical(y_val_, num_classes=10)\n",
    "\n",
    "        hist = train_model.fit_generator(generator=train_generator(x_train_, y_train_, args.batch_size),\n",
    "                            steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
    "                            epochs=args.epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data = [[x_val_, y_val_], [y_val_, x_val_]],\n",
    "                            callbacks=[callbacks.LearningRateScheduler(lr_schedule), log, tb, checkpoint, time_callback])\n",
    "\n",
    "    train_model.save(args.save_dir + '/trained_model.h5')\n",
    "    print(time_callback.times)\n",
    "    # writedata.py\n",
    "    f = open(args.save_dir+'/time.txt', 'w')\n",
    "    for t in time_callback.times:\n",
    "        f.write(str(t)+'\\n')\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def load_mnist():\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    from keras.datasets import mnist\n",
    "    from keras.utils import to_categorical\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "    y_train = to_categorical(y_train.astype('float32'))\n",
    "    y_test = to_categorical(y_test.astype('float32'))\n",
    "#     return (x_train[:500,...], y_train[:500,...]), (x_test, y_test)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def cifar10():\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    from keras.datasets import cifar10\n",
    "    from keras.utils import to_categorical\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    x_train = x_train.reshape(-1, 32, 32, 3).astype('float32') / 255.\n",
    "    x_test = x_test.reshape(-1, 32, 32, 3).astype('float32') / 255.\n",
    "    y_train = to_categorical(y_train.astype('float32'))\n",
    "    y_test = to_categorical(y_test.astype('float32'))\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def prepare_affNIST(path):\n",
    "    from scipy.io import loadmat\n",
    "    from sklearn.utils import shuffle\n",
    "    \n",
    "    afftest = loadmat(path)\n",
    "    afftest_images = afftest['affNISTdata']['image'][0][0].transpose()\n",
    "    afftest_images = afftest_images.reshape((afftest_images.shape[0], 40, 40, 1)).astype(np.float64) /255.\n",
    "\n",
    "    afftest_labels = afftest['affNISTdata']['label_int'][0][0].transpose()\n",
    "    afftest_labels = afftest_labels.reshape((afftest_labels.shape[0])).astype(np.int64) \n",
    "    afftest_images, afftest_labels = shuffle(afftest_images, afftest_labels)\n",
    "    \n",
    "    return afftest_images, afftest_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.args object at 0x000002B021085470>\n"
     ]
    }
   ],
   "source": [
    "class args:\n",
    "    epochs=50\n",
    "    batch_size=100\n",
    "    #debug='store_true'\n",
    "    debug=0\n",
    "    save_dir='./result'\n",
    "    augment='False'\n",
    "    gpu='0'\n",
    "    dataset='mnist'\n",
    "    layernum=0\n",
    "    dimcaps=16\n",
    "    validratio=1\n",
    "    shift_fraction=0.1\n",
    "args= args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.args object at 0x000002B021085470>\n",
      "layer num :  0\n",
      "dim_caps :  16\n",
      "WARNING:tensorflow:From C:\\Users\\Choi\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "primary caps shape :  (?, 14, 14, 16, 8)\n",
      "WARNING:tensorflow:From C:\\Users\\Choi\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Final Routing caps shape :  (?, 10, 16)\n",
      "Length shape :  (?, 10)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 64)   640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28, 28, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28, 28, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "primary_cap_1 (PrimaryCap)      (None, 14, 14, 16, 8 76032       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 14, 14, 16, 8 0           primary_cap_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fully_conv_caps_1 (FullyConvCap (None, 10, 16)       4028320     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 16)       0           fully_conv_caps_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_1 (Mask)                   (None, 160)          0           activation_4[0][0]               \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "length_1 (Length)               (None, 10)           0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 28, 28, 1)    747280      mask_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,889,712\n",
      "Trainable params: 4,889,456\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "valid_ratio 0.1\n",
      "WARNING:tensorflow:From C:\\Users\\Choi\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 19s 357us/step - loss: 0.0737 - length_1_loss: 0.0584 - decoder_loss: 0.0509 - length_1_acc: 0.9553 - decoder_acc: 0.7943 - val_loss: 0.0260 - val_length_1_loss: 0.0138 - val_decoder_loss: 0.0407 - val_length_1_acc: 0.9855 - val_decoder_acc: 0.7979\n",
      "\n",
      "Epoch 00001: val_length_1_acc improved from -inf to 0.98550, saving model to ./result/weights-01.h5\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 17s 312us/step - loss: 0.0264 - length_1_loss: 0.0146 - decoder_loss: 0.0393 - length_1_acc: 0.9861 - decoder_acc: 0.7985 - val_loss: 0.0193 - val_length_1_loss: 0.0086 - val_decoder_loss: 0.0356 - val_length_1_acc: 0.9910 - val_decoder_acc: 0.8018\n",
      "\n",
      "Epoch 00002: val_length_1_acc improved from 0.98550 to 0.99100, saving model to ./result/weights-02.h5\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 17s 312us/step - loss: 0.0208 - length_1_loss: 0.0103 - decoder_loss: 0.0352 - length_1_acc: 0.9905 - decoder_acc: 0.8008 - val_loss: 0.0174 - val_length_1_loss: 0.0076 - val_decoder_loss: 0.0324 - val_length_1_acc: 0.9910 - val_decoder_acc: 0.8028\n",
      "\n",
      "Epoch 00003: val_length_1_acc did not improve from 0.99100\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 17s 312us/step - loss: 0.0179 - length_1_loss: 0.0080 - decoder_loss: 0.0328 - length_1_acc: 0.9927 - decoder_acc: 0.8021 - val_loss: 0.0169 - val_length_1_loss: 0.0076 - val_decoder_loss: 0.0309 - val_length_1_acc: 0.9908 - val_decoder_acc: 0.8034\n",
      "\n",
      "Epoch 00004: val_length_1_acc did not improve from 0.99100\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 17s 312us/step - loss: 0.0160 - length_1_loss: 0.0066 - decoder_loss: 0.0314 - length_1_acc: 0.9937 - decoder_acc: 0.8028 - val_loss: 0.0165 - val_length_1_loss: 0.0077 - val_decoder_loss: 0.0296 - val_length_1_acc: 0.9920 - val_decoder_acc: 0.8044\n",
      "\n",
      "Epoch 00005: val_length_1_acc improved from 0.99100 to 0.99200, saving model to ./result/weights-05.h5\n",
      "[19.568005323410034, 16.89173984527588, 16.85278034210205, 16.835797786712646, 16.91371774673462]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import argparse\n",
    "    \n",
    "# setting the hyper parameters\n",
    "parser = argparse.ArgumentParser(description=\"AR Capsule Network on MNIST, CIFAR10, and affNIST.\")\n",
    "parser.add_argument('--epochs', default=50, type=int)\n",
    "parser.add_argument('--batch_size', default=100, type=int)\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                    help=\"Save weights by TensorBoard\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "#    parser.add_argument('-t', '--testing', action='store_true',\n",
    "#                        help=\"Test the trained model on testing dataset\")\n",
    "#    parser.add_argument('-w', '--weights', default=None,\n",
    "#                        help=\"The path of the saved weights. Should be specified when testing\")\n",
    "parser.add_argument('--augment', default='False',help=\"augmentation\")\n",
    "parser.add_argument('--gpu', default=\"0\",help=\"gpu\")\n",
    "parser.add_argument('--dataset', default=\"mnist\", help=\"dataset\")\n",
    "parser.add_argument('--layernum', default=\"0\", help=\"layernum\")\n",
    "parser.add_argument('--dimcaps', default=\"16\", help=\"dimcaps\")\n",
    "parser.add_argument('--validratio', default=\"1\", help=\"validratio\")\n",
    "parser.add_argument('--shift_fraction', default='0.1', help=\"shift_fraction\")\n",
    "#parser.add_argument('--log_dir', default='./result')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "'''\n",
    "print(args)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir)\n",
    "\n",
    "# load data\n",
    "assert(args.dataset in ['mnist', 'cifar10', 'affnist'])\n",
    "if args.dataset == 'mnist':\n",
    "    (x_train, y_train), (x_test, y_test) = load_mnist()\n",
    "elif args.dataset == 'cifar10':\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10()\n",
    "elif args.dataset == 'affnist':\n",
    "    assert(args.augment == 'True')\n",
    "    (x_train, y_train), (_, _) = load_mnist()\n",
    "    x_train = np.pad(x_train, ((0,0), (6,6),(6,6),(0,0)), mode='constant') \n",
    "\n",
    "model = AR_CapsNet(x_train[0].shape, args)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train(model, x_train, y_train, args)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
