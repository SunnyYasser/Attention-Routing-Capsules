{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import keras\n",
    "from ar_capsulelayers import Mask, margin_loss, PrimaryCap, Length, margin_loss, ConvCaps, FullyConvCaps\n",
    "import os\n",
    "from ar_capsulenet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "## MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--epochs EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                             [--debug] [--save_dir SAVE_DIR]\n",
      "                             [--augment AUGMENT] [--gpu GPU]\n",
      "                             [--dataset DATASET] [--layernum LAYERNUM]\n",
      "                             [--dimcaps DIMCAPS] [--validratio VALIDRATIO]\n",
      "                             [--shift_fraction SHIFT_FRACTION]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Choi\\AppData\\Roaming\\jupyter\\runtime\\kernel-fd3c7c2f-4a69-41da-9bf9-8c1e65a96a91.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Choi\\Anaconda3\\envs\\py35\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "# setting the hyper parameters\n",
    "parser = argparse.ArgumentParser(description=\"AR Capsule Network on MNIST, CIFAR10, and affNIST.\")\n",
    "parser.add_argument('--epochs', default=50, type=int)\n",
    "parser.add_argument('--batch_size', default=100, type=int)\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                    help=\"Save weights by TensorBoard\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "#    parser.add_argument('-t', '--testing', action='store_true',\n",
    "#                        help=\"Test the trained model on testing dataset\")\n",
    "#    parser.add_argument('-w', '--weights', default=None,\n",
    "#                        help=\"The path of the saved weights. Should be specified when testing\")\n",
    "parser.add_argument('--augment', default='False',help=\"augmentation\")\n",
    "parser.add_argument('--gpu', default=\"0\",help=\"gpu\")\n",
    "parser.add_argument('--dataset', default=\"mnist\", help=\"dataset\")\n",
    "parser.add_argument('--layernum', default=\"0\", help=\"layernum\")\n",
    "parser.add_argument('--dimcaps', default=\"16\", help=\"dimcaps\")\n",
    "parser.add_argument('--validratio', default=\"1\", help=\"validratio\")\n",
    "parser.add_argument('--shift_fraction', default='0.1', help=\"shift_fraction\")\n",
    "#parser.add_argument('--log_dir', default='./result')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    epochs=50\n",
    "    batch_size=100\n",
    "    debug='store_true'\n",
    "    save_dir='./result'\n",
    "    augment=False\n",
    "    gpu='0'\n",
    "    dataset='mnist'\n",
    "    layernum=0\n",
    "    dimcaps=16\n",
    "    validratio=1\n",
    "    shift_fraction=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.shift_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AR_CapsNet(args=args):\n",
    "    input_shape = x_train[0].shape\n",
    "    dim_caps = int(args.dimcaps)\n",
    "    layernum = int(args.layernum)\n",
    "    \n",
    "    kernel_regularizer=regularizers.l2(0)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    conv1 = Conv2d_bn(input_tensor = input_layer, filters=64, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                     kernel_regularizer=kernel_regularizer)\n",
    "    conv1 = Conv2d_bn(input_tensor = conv1, filters=64, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                     kernel_regularizer=kernel_regularizer)\n",
    "\n",
    "    ## Primary Capsules\n",
    "    primarycaps = PrimaryCap(n_channels=8, dim_capsule=16, decrease_resolution=True, kernel_regularizer=kernel_regularizer)(conv1)\n",
    "    primarycaps = Activation('tanh')(primarycaps)\n",
    "    print('primary caps shape : ', primarycaps.shape)\n",
    "    \n",
    "    ## Convolutional Capsules\n",
    "    if layernum == 0:\n",
    "        out = primarycaps\n",
    "    elif layernum == 1:\n",
    "        ConvCaps1 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = True, kernel_regularizer=kernel_regularizer)(primarycaps)\n",
    "        ConvCaps1 = Activation('tanh')(ConvCaps1)\n",
    "        print('ConvCaps1 shape : ', ConvCaps1.shape)\n",
    "        out = ConvCaps1\n",
    "        \n",
    "    elif layernum == 2:\n",
    "        ConvCaps1 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = True, kernel_regularizer=kernel_regularizer)(primarycaps)\n",
    "        ConvCaps1 = Activation('tanh')(ConvCaps1)\n",
    "        print('ConvCaps1 shape : ', ConvCaps1.shape)\n",
    "        \n",
    "        ConvCaps2 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = False, kernel_regularizer=kernel_regularizer)(ConvCaps1)\n",
    "        ConvCaps2 = Activation('tanh')(Add()([ConvCaps1 , ConvCaps2]))\n",
    "        print('ConvCaps2 shape : ', ConvCaps2.shape)\n",
    "        out = ConvCaps2\n",
    "        \n",
    "    elif layernum == 3:\n",
    "        ConvCaps1 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = True, kernel_regularizer=kernel_regularizer)(primarycaps)\n",
    "        ConvCaps1 = Activation('tanh')(ConvCaps1)\n",
    "        print('ConvCaps1 shape : ', ConvCaps1.shape)\n",
    "        \n",
    "        ConvCaps2 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = False, kernel_regularizer=kernel_regularizer)(ConvCaps1)\n",
    "        ConvCaps2 = Activation('tanh')(Add()([ConvCaps1 , ConvCaps2]))\n",
    "        print('ConvCaps2 shape : ', ConvCaps2.shape)\n",
    "        \n",
    "        ConvCaps3 = ConvCaps(n_channels=8, dim_capsule=dim_caps, decrease_resolution = False, kernel_regularizer=kernel_regularizer)(ConvCaps2)\n",
    "        ConvCaps3 = Activation('tanh')(Add()([ConvCaps2 , ConvCaps3]))\n",
    "        print('ConvCaps3 shape : ', ConvCaps3.shape)\n",
    "        out = ConvCaps3\n",
    "        \n",
    "    ## Fully Convolutional Capsules\n",
    "    output_dim_capsule = dim_caps\n",
    "    outputs = FullyConvCaps(n_channels=10, dim_capsule=output_dim_capsule, kernel_regularizer=kernel_regularizer)(out)\n",
    "    outputs = Activation('tanh')(outputs)\n",
    "    print('Final Routing caps shape : ', outputs.shape)\n",
    "\n",
    "    ## Length Capsules\n",
    "    real_outputs = Length()(outputs)\n",
    "    print('Length shape : ', real_outputs.shape)\n",
    "\n",
    "\n",
    "    from keras import models\n",
    "\n",
    "    n_class=10\n",
    "\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([outputs, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(outputs)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "    # Shared Decoder model in training and prediction\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(512, activation='relu', input_dim=output_dim_capsule*n_class, kernel_regularizer=kernel_regularizer))\n",
    "    decoder.add(layers.Dense(512, activation='relu', kernel_regularizer=kernel_regularizer))\n",
    "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid', kernel_regularizer=kernel_regularizer))\n",
    "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "    train_model = models.Model([input_layer, y], [real_outputs, decoder(masked_by_y)])\n",
    "    eval_model = models.Model(input_layer, [real_outputs, decoder(masked)])\n",
    "\n",
    "    # manipulate model\n",
    "    noise = layers.Input(shape=(n_class, output_dim_capsule))\n",
    "    noised_outputs = layers.Add()([outputs, noise])\n",
    "    masked_noised_y = Mask()([noised_outputs, y])\n",
    "    manipulate_model = models.Model([input_layer, y, noise], [outputs, decoder(masked_noised_y)])\n",
    "\n",
    "    return eval_model, manipulate_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary caps shape :  (?, 14, 14, 16, 8)\n",
      "ConvCaps1 shape :  (?, 7, 7, 32, 8)\n",
      "Final Routing caps shape :  (?, 10, 32)\n",
      "Length shape :  (?, 10)\n",
      "primary caps shape :  (?, 14, 14, 16, 8)\n",
      "ConvCaps1 shape :  (?, 7, 7, 32, 8)\n",
      "Final Routing caps shape :  (?, 10, 32)\n",
      "Length shape :  (?, 10)\n",
      "primary caps shape :  (?, 14, 14, 16, 8)\n",
      "ConvCaps1 shape :  (?, 7, 7, 32, 8)\n",
      "Final Routing caps shape :  (?, 10, 32)\n",
      "Length shape :  (?, 10)\n",
      "pred1\n",
      "acc :  0.9947\n",
      "pred2\n",
      "acc :  0.9945\n",
      "pred3\n",
      "acc :  0.9945\n",
      "Total acc :  0.9945666666666667\n",
      "acc :  0.9949\n"
     ]
    }
   ],
   "source": [
    "''' WITHOUT AUGMENTATION '''\n",
    "\n",
    "model_1, manipulate_model_1 = AR_CapsNet()\n",
    "model_path = './result/mnist_test/1/weights-18.h5'\n",
    "model_1.load_weights(model_path)\n",
    "manipulate_model_1.load_weights(model_path)\n",
    "\n",
    "model_2, _ = AR_CapsNet()\n",
    "model_path = './result/mnist_test/2/weights-19.h5'\n",
    "model_2.load_weights(model_path)\n",
    "\n",
    "model_3, _ = AR_CapsNet()\n",
    "model_path = './result/mnist_test/2/weights-19.h5'\n",
    "model_3.load_weights(model_path)\n",
    "\n",
    "y_label = np.argmax(y_test, axis=1)\n",
    "\n",
    "pred1, _ = model_1.predict(x=x_test, batch_size=100)\n",
    "print('pred1')\n",
    "pred_label = np.argmax(pred1, axis=1)\n",
    "acc1 = np.sum(y_label == pred_label) / float(y_label.shape[0])\n",
    "print('acc : ', acc1)\n",
    "\n",
    "pred2, _ = model_2.predict(x=x_test, batch_size=100)\n",
    "print('pred2')\n",
    "pred_label = np.argmax(pred2, axis=1)\n",
    "acc2 = np.sum(y_label == pred_label) / float(y_label.shape[0])\n",
    "print('acc : ', acc2)\n",
    "\n",
    "pred3, _ = model_3.predict(x=x_test, batch_size=100)\n",
    "print('pred3')\n",
    "pred_label = np.argmax(pred3, axis=1)\n",
    "acc3 = np.sum(y_label == pred_label) / float(y_label.shape[0])\n",
    "print('acc : ', acc3)\n",
    "\n",
    "print('Total acc : ', (acc1 + acc2 + acc3)/3)\n",
    "\n",
    "pred_ensemble = (pred1 + pred2 + pred3) / 3\n",
    "\n",
    "y_label = np.argmax(y_test, axis=1)\n",
    "pred_label = np.argmax(pred_ensemble, axis=1)\n",
    "\n",
    "print('acc : ', np.sum(y_label == pred_label) / float(y_label.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary caps shape :  (?, 14, 14, 16, 8)\n",
      "ConvCaps1 shape :  (?, 7, 7, 32, 8)\n",
      "Final Routing caps shape :  (?, 10, 32)\n",
      "Length shape :  (?, 10)\n",
      "primary caps shape :  (?, 14, 14, 16, 8)\n",
      "ConvCaps1 shape :  (?, 7, 7, 32, 8)\n",
      "Final Routing caps shape :  (?, 10, 32)\n",
      "Length shape :  (?, 10)\n",
      "primary caps shape :  (?, 14, 14, 16, 8)\n",
      "ConvCaps1 shape :  (?, 7, 7, 32, 8)\n",
      "Final Routing caps shape :  (?, 10, 32)\n",
      "Length shape :  (?, 10)\n",
      "pred1\n",
      "acc :  0.9944\n",
      "pred2\n",
      "acc :  0.9949\n",
      "pred3\n",
      "acc :  0.9944\n",
      "Total acc :  0.9945666666666666\n",
      "acc :  0.9958\n"
     ]
    }
   ],
   "source": [
    "''' WITH AUGMENTATION '''\n",
    "\n",
    "model_1, manipulate_model_1 = AR_CapsNet()\n",
    "model_path = './result/mnist_test_aug/1/weights-20.h5'\n",
    "model_1.load_weights(model_path)\n",
    "manipulate_model_1.load_weights(model_path)\n",
    "\n",
    "model_2, _ = AR_CapsNet()\n",
    "model_path = './result/mnist_test_aug/2/weights-20.h5'\n",
    "model_2.load_weights(model_path)\n",
    "\n",
    "model_3, _ = AR_CapsNet()\n",
    "model_path = './result/mnist_test_aug/3/weights-15.h5'\n",
    "model_3.load_weights(model_path)\n",
    "\n",
    "y_label = np.argmax(y_test, axis=1)\n",
    "\n",
    "pred1, _ = model_1.predict(x=x_test, batch_size=100)\n",
    "print('pred1')\n",
    "pred_label = np.argmax(pred1, axis=1)\n",
    "acc1 = np.sum(y_label == pred_label) / float(y_label.shape[0])\n",
    "print('acc : ', acc1)\n",
    "\n",
    "pred2, _ = model_2.predict(x=x_test, batch_size=100)\n",
    "print('pred2')\n",
    "pred_label = np.argmax(pred2, axis=1)\n",
    "acc2 = np.sum(y_label == pred_label) / float(y_label.shape[0])\n",
    "print('acc : ', acc2)\n",
    "\n",
    "pred3, _ = model_3.predict(x=x_test, batch_size=100)\n",
    "print('pred3')\n",
    "pred_label = np.argmax(pred3, axis=1)\n",
    "acc3 = np.sum(y_label == pred_label) / float(y_label.shape[0])\n",
    "print('acc : ', acc3)\n",
    "\n",
    "print('Total acc : ', (acc1 + acc2 + acc3)/3)\n",
    "\n",
    "pred_ensemble = (pred1 + pred2 + pred3) / 3\n",
    "\n",
    "y_label = np.argmax(y_test, axis=1)\n",
    "pred_label = np.argmax(pred_ensemble, axis=1)\n",
    "\n",
    "print('acc : ', np.sum(y_label == pred_label) / float(y_label.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMATION EQUIVARIANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 22:04:11.583242  1788 deprecation_wrapper.py:119] From c:\\users\\choi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0731 22:04:11.600245  1788 deprecation_wrapper.py:119] From c:\\users\\choi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0731 22:04:11.603248  1788 deprecation_wrapper.py:119] From c:\\users\\choi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0731 22:04:11.666260  1788 deprecation_wrapper.py:119] From c:\\users\\choi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0731 22:04:11.667251  1788 deprecation_wrapper.py:119] From c:\\users\\choi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0731 22:04:12.750415  1788 deprecation_wrapper.py:119] From c:\\users\\choi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0731 22:04:12.919453  1788 deprecation.py:506] From c:\\users\\choi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary caps shape :  (?, 14, 14, 16, 8)\n",
      "ConvCaps1 shape :  (?, 7, 7, 32, 8)\n",
      "Final Routing caps shape :  (?, 10, 32)\n",
      "Length shape :  (?, 10)\n"
     ]
    }
   ],
   "source": [
    "''' WITHOUT AUG'''\n",
    "model, manipulate_model = AR_CapsNet()\n",
    "model_path = './result/mnist_test/1/weights-18.h5'\n",
    "model.load_weights(model_path)\n",
    "manipulate_model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary caps shape :  (?, 14, 14, 16, 8)\n",
      "ConvCaps1 shape :  (?, 7, 7, 32, 8)\n",
      "Final Routing caps shape :  (?, 10, 32)\n",
      "Length shape :  (?, 10)\n"
     ]
    }
   ],
   "source": [
    "''' WITH AUGMENTATION '''\n",
    "model, manipulate_model = AR_CapsNet()\n",
    "model_path = './result/mnist_test_aug/3/weights-15.h5'\n",
    "model.load_weights(model_path)\n",
    "manipulate_model.load_weights(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "def combine_images(generated_images, height=None, width=None):\n",
    "    num = generated_images.shape[0]\n",
    "    if width is None and height is None:\n",
    "        width = int(math.sqrt(num))\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif width is not None and height is None:  # height not given\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif height is not None and width is None:  # width not given\n",
    "        width = int(math.ceil(float(num)/height))\n",
    "\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image\n",
    "\n",
    "def manipulate_latent(model, data, digit, output_dim_capsule, save_dir='./result/'):\n",
    "    \"\"\" digit : digit to manipulate \"\"\"\n",
    "    print('-'*30 + 'Begin: manipulate' + '-'*30)\n",
    "    x_test, y_test = data\n",
    "    index = np.argmax(y_test, 1) == digit\n",
    "    number = np.random.randint(low=0, high=sum(index) - 1)\n",
    "    x, y = x_test[index][number], y_test[index][number]\n",
    "    x, y = np.expand_dims(x, 0), np.expand_dims(y, 0)\n",
    "    noise = np.zeros([1, 10, output_dim_capsule])\n",
    "    x_recons = []\n",
    "    logits = []\n",
    "    for dim in range(output_dim_capsule):\n",
    "        for r in np.array([-0.25, -0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25]) * np.sqrt(output_dim_capsule):\n",
    "            tmp = np.copy(noise)\n",
    "            tmp[:,:,dim] = r\n",
    "            #print(r)\n",
    "            logit, x_recon = model.predict([x, y, tmp])\n",
    "            x_recons.append(x_recon)\n",
    "            \n",
    "            #plt.imshow(x_recon[0,:,:,0], cmap='gray')\n",
    "            #plt.show()\n",
    "            \n",
    "            logits.append(logit)\n",
    "\n",
    "    x_recons = np.concatenate(x_recons)\n",
    "#    print(x_recons.shape)\n",
    "\n",
    "    img = combine_images(x_recons, height=output_dim_capsule)\n",
    "    image = img*255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(save_dir + '/manipulate-%d.png' % digit)\n",
    "    print('manipulated result saved to %s/manipulate-%d.png' % (save_dir, digit))\n",
    "    print('-' * 30 + 'End: manipulate' + '-' * 30)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-0.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-1.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-2.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-3.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-4.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-5.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-6.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-7.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-8.png\n",
      "------------------------------End: manipulate------------------------------\n",
      "------------------------------Begin: manipulate------------------------------\n",
      "manipulated result saved to ./result//manipulate-9.png\n",
      "------------------------------End: manipulate------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Save Manipulated Images \"\"\"\n",
    "for i in range(10):\n",
    "    logits = manipulate_latent(manipulate_model, (x_test, y_test), i, output_dim_capsule=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "primary_cap_4 (PrimaryCap)   (None, 14, 14, 16, 8)     76032     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 14, 14, 16, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv_caps_4 (ConvCaps)       (None, 7, 7, 32, 8)       321792    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 7, 7, 32, 8)       0         \n",
      "_________________________________________________________________\n",
      "fully_conv_caps_4 (FullyConv (None, 10, 32)            4047680   \n",
      "=================================================================\n",
      "Total params: 4,483,584\n",
      "Trainable params: 4,483,328\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 7\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a = model\n",
    "inputs = a.inputs\n",
    "outputs = a.layers[-5]\n",
    "from keras import models\n",
    "experiment_model = models.Model(inputs=inputs, outputs = outputs.output)\n",
    "\n",
    "experiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n",
      "0 x -1 0.83048004\n",
      "980\n",
      "0 x 1 0.79548043\n",
      "980\n",
      "0 y -1 0.8736545\n",
      "980\n",
      "0 y 1 0.7638994\n",
      "980\n",
      "0 r -1 0.8749596\n",
      "980\n",
      "0 r 1 0.8794984\n",
      "1135\n",
      "1 x -1 0.87522596\n",
      "1135\n",
      "1 x 1 0.8107506\n",
      "1135\n",
      "1 y -1 0.79415065\n",
      "1135\n",
      "1 y 1 0.8562171\n",
      "1135\n",
      "1 r -1 0.83535916\n",
      "1135\n",
      "1 r 1 0.8635535\n",
      "1032\n",
      "2 x -1 0.81639457\n",
      "1032\n",
      "2 x 1 0.80979824\n",
      "1032\n",
      "2 y -1 0.8211581\n",
      "1032\n",
      "2 y 1 0.8832079\n",
      "1032\n",
      "2 r -1 0.8500662\n",
      "1032\n",
      "2 r 1 0.85621923\n",
      "1010\n",
      "3 x -1 0.7916326\n",
      "1010\n",
      "3 x 1 0.8537083\n",
      "1010\n",
      "3 y -1 0.8246144\n",
      "1010\n",
      "3 y 1 0.85421276\n",
      "1010\n",
      "3 r -1 0.87377214\n",
      "1010\n",
      "3 r 1 0.8872639\n",
      "982\n",
      "4 x -1 0.79958576\n",
      "982\n",
      "4 x 1 0.8037997\n",
      "982\n",
      "4 y -1 0.8346847\n",
      "982\n",
      "4 y 1 0.81180394\n",
      "982\n",
      "4 r -1 0.88833135\n",
      "982\n",
      "4 r 1 0.8766547\n",
      "892\n",
      "5 x -1 0.8496681\n",
      "892\n",
      "5 x 1 0.84253484\n",
      "892\n",
      "5 y -1 0.773073\n",
      "892\n",
      "5 y 1 0.8092853\n",
      "892\n",
      "5 r -1 0.8473955\n",
      "892\n",
      "5 r 1 0.90799457\n",
      "958\n",
      "6 x -1 0.8388635\n",
      "958\n",
      "6 x 1 0.819161\n",
      "958\n",
      "6 y -1 0.8048186\n",
      "958\n",
      "6 y 1 0.7666618\n",
      "958\n",
      "6 r -1 0.87721086\n",
      "958\n",
      "6 r 1 0.8885206\n",
      "1028\n",
      "7 x -1 0.8548349\n",
      "1028\n",
      "7 x 1 0.8488038\n",
      "1028\n",
      "7 y -1 0.7691454\n",
      "1028\n",
      "7 y 1 0.8170794\n",
      "1028\n",
      "7 r -1 0.86712736\n",
      "1028\n",
      "7 r 1 0.86377597\n",
      "974\n",
      "8 x -1 0.8200206\n",
      "974\n",
      "8 x 1 0.8203462\n",
      "974\n",
      "8 y -1 0.80808306\n",
      "974\n",
      "8 y 1 0.74160284\n",
      "974\n",
      "8 r -1 0.8732348\n",
      "974\n",
      "8 r 1 0.89115274\n",
      "1009\n",
      "9 x -1 0.83544654\n",
      "1009\n",
      "9 x 1 0.87732977\n",
      "1009\n",
      "9 y -1 0.792459\n",
      "1009\n",
      "9 y 1 0.7767549\n",
      "1009\n",
      "9 r -1 0.8879686\n",
      "1009\n",
      "9 r 1 0.8701316\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "x_cos = []\n",
    "y_cos = []\n",
    "r_cos = []\n",
    "\n",
    "for num in range(10):\n",
    "    for trans in ['x', 'y', 'r']:\n",
    "        align_vector_pos_list = []\n",
    "        align_vector_neg_list = []\n",
    "        \n",
    "        for sign in [-1, 1]: \n",
    "            ind = (y_test[:,num] == 1)\n",
    "            sample = x_test[ind]\n",
    "            print(sample.shape[0])\n",
    "            img = x_test[0,:,:,0]\n",
    "            rows,cols = img.shape\n",
    "            variation = np.zeros((sample.shape[0]*5,28,28,1))\n",
    "            for i in range(sample.shape[0]):\n",
    "                for j in range(5):\n",
    "                    img = sample[i,...,0]\n",
    "                    if trans == 'x':\n",
    "                        M = np.float32([[1,0,sign*(j+1)],[0,1,0]]) #x    \n",
    "                    elif trans == 'y':\n",
    "                        M = np.float32([[1,0,0],[0,1,sign*(j+1)]]) #y\n",
    "                    elif trans == 'r':\n",
    "                        M = cv2.getRotationMatrix2D((cols/2,rows/2), sign*5*(j+1),1) # 회전\n",
    "\n",
    "                    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "                    variation[i*5+j,...,0] = dst\n",
    "\n",
    "            capsules = experiment_model.predict([variation])\n",
    "            sample_repeat = sample.repeat(5, axis=0)\n",
    "            ori_caps = experiment_model.predict([sample_repeat])\n",
    "            _transform = (capsules[:,num,:]-ori_caps[:,num,:])\n",
    "\n",
    "\n",
    "            m = []\n",
    "            for i in range(sample.shape[0]):\n",
    "            # for i in range(10):\n",
    "                stat=[]\n",
    "                U, S, VT = np.linalg.svd(_transform[5*i:5*(i+1)])\n",
    "                align_vector = VT[0,:]\n",
    "                if sign == 1:\n",
    "                    align_vector_pos_list.append(align_vector)\n",
    "                elif sign == -1:\n",
    "                    align_vector_neg_list.append(align_vector)\n",
    "\n",
    "                for j in range(5):\n",
    "                    a = _transform[5*i:5*i+5][j,:]\n",
    "                    stat.append(np.dot(align_vector,a)/np.linalg.norm(a))\n",
    "                m.append(np.mean(np.abs(stat)))\n",
    "\n",
    "            print(num, trans, sign, np.mean(m))\n",
    "            data[num, trans, sign, 'mean'] = np.mean(m)\n",
    "            data[num, trans, sign, 'std']  = np.std(m)\n",
    "        \n",
    "        if trans == 'x':\n",
    "            x_cos.extend([np.dot(p, n) for p, n in zip(align_vector_pos_list, align_vector_neg_list)])\n",
    "        if trans == 'y':\n",
    "            y_cos.extend([np.dot(p, n) for p, n in zip(align_vector_pos_list, align_vector_neg_list)])\n",
    "        if trans == 'r':\n",
    "            r_cos.extend([np.dot(p, n) for p, n in zip(align_vector_pos_list, align_vector_neg_list)])\n",
    "\n",
    "        data[num, trans, 0, 'cos'] = [np.dot(p, n) for p, n in zip(align_vector_pos_list, align_vector_neg_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_cos = []\n",
    "t_cos.extend(x_cos)\n",
    "t_cos.extend(y_cos)\n",
    "t_cos.extend(r_cos)\n",
    "\n",
    "f = plt.figure()\n",
    "plt.hist(t_cos, bins =20)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Cosine similarity')\n",
    "plt.ylabel('The number of ')\n",
    "plt.show()\n",
    "\n",
    "f.savefig(\"hist_ours.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_pos_mean = pd.DataFrame.from_dict({'num':np.array(range(10)), \n",
    "                                     'x translation': [data[i, 'x', 1, 'mean'] for i in range(10)],\n",
    "                                     'y translation': [data[i, 'y', 1, 'mean'] for i in range(10)],\n",
    "                                     'rotation translation': [data[i, 'r', 1, 'mean'] for i in range(10)],\n",
    "                                    })\n",
    "df_pos_std = pd.DataFrame.from_dict({'num':np.array(range(10)), \n",
    "                                     'x translation': [data[i, 'x', 1, 'std'] for i in range(10)],\n",
    "                                     'y translation': [data[i, 'y', 1, 'std'] for i in range(10)],\n",
    "                                     'rotation translation': [data[i, 'r', 1, 'std'] for i in range(10)],\n",
    "                            })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_neg_mean = pd.DataFrame.from_dict({'num':np.array(range(10)), \n",
    "                                     'x translation': [data[i, 'x', -1, 'mean'] for i in range(10)],\n",
    "                                     'y translation': [data[i, 'y', -1, 'mean'] for i in range(10)],\n",
    "                                     'rotation translation': [data[i, 'r', -1, 'mean'] for i in range(10)],\n",
    "                                    })\n",
    "df_neg_std = pd.DataFrame.from_dict({'num':np.array(range(10)), \n",
    "                                     'x translation': [data[i, 'x', -1, 'std'] for i in range(10)],\n",
    "                                     'y translation': [data[i, 'y', -1, 'std'] for i in range(10)],\n",
    "                                     'rotation translation': [data[i, 'r', -1, 'std'] for i in range(10)],\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num  x translation  y translation  rotation translation\n",
      "0    0       0.795480       0.763899              0.879498\n",
      "1    1       0.810751       0.856217              0.863554\n",
      "2    2       0.809798       0.883208              0.856219\n",
      "3    3       0.853708       0.854213              0.887264\n",
      "4    4       0.803800       0.811804              0.876655\n",
      "5    5       0.842535       0.809285              0.907995\n",
      "6    6       0.819161       0.766662              0.888521\n",
      "7    7       0.848804       0.817079              0.863776\n",
      "8    8       0.820346       0.741603              0.891153\n",
      "9    9       0.877330       0.776755              0.870132\n",
      "   num  x translation  y translation  rotation translation\n",
      "0    0       0.830480       0.873654              0.874960\n",
      "1    1       0.875226       0.794151              0.835359\n",
      "2    2       0.816395       0.821158              0.850066\n",
      "3    3       0.791633       0.824614              0.873772\n",
      "4    4       0.799586       0.834685              0.888331\n",
      "5    5       0.849668       0.773073              0.847395\n",
      "6    6       0.838863       0.804819              0.877211\n",
      "7    7       0.854835       0.769145              0.867127\n",
      "8    8       0.820021       0.808083              0.873235\n",
      "9    9       0.835447       0.792459              0.887969\n"
     ]
    }
   ],
   "source": [
    "print(df_pos_mean)\n",
    "print(df_neg_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_for_digit = []\n",
    "\n",
    "for digit in range(10):\n",
    "    mean = 0\n",
    "    for trans in ['x', 'y', 'r']:\n",
    "        for sign in [1, -1]:\n",
    "            mean += data[digit, trans, sign, 'mean']\n",
    "            \n",
    "    mean_for_digit.append(mean/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8440065483252207, 0.8582447270552317, 0.8360079924265543, 0.8362869421641032, 0.8485727608203888, 0.8328078786532084, 0.855571448802948, 0.8382324874401093, 0.8789799312750498, 0.8388866086800894]\n",
      "5\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(mean_for_digit)\n",
    "print(np.argmin(mean_for_digit))\n",
    "print(np.argmax(mean_for_digit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8784765243530274, 0.8675425529479981, 0.8080725371837616, 0.8095841467380523, 0.8281712889671325, 0.8312152564525604]\n"
     ]
    }
   ],
   "source": [
    "mean_for_trans = []\n",
    "\n",
    "for trans in ['r', 'y', 'x']:\n",
    "    for sign in [1, -1]:\n",
    "        mean = 0\n",
    "        for digit in range(10):\n",
    "                mean += data[digit, trans, sign, 'mean']\n",
    "\n",
    "        mean_for_trans.append(mean/10)\n",
    "print(mean_for_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
